{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Play Movie Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import random\n",
    "\n",
    "client = MongoClient(\"10.120.28.17\", 27017)\n",
    "\n",
    "#我們自己訂的db 和 collection\n",
    "db = client.googleplay\n",
    "collect = db.googleplay_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_payload(url, querystring, headers):\n",
    "    \"\"\" This is the function for create payload for google_play_movie()  to use\n",
    "          arg = url, querystring, headers from google_play_movie()\n",
    "          return  = 'payload_list'\n",
    "    \"\"\"\n",
    "    print \"111\"\n",
    "    # get first movie url in the page for further compare with the urls get from payload\n",
    "    payload_first = \"-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"start\\\"\\r\\n\\r\\n0\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"num\\\"\\r\\n\\r\\n60\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"numChildren\\\"\\r\\n\\r\\n0\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"ipf\\\"\\r\\n\\r\\n1\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"xhr\\\"\\r\\n\\r\\n1\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"h1\\\"\\r\\n\\r\\nzh_TW\\r\\n-----011000010111000001101001--\"\n",
    "    url_first = url\n",
    "    print url_first\n",
    "    querystring_first = querystring\n",
    "    print querystring_first\n",
    "    headers_first = headers\n",
    "    print headers_first\n",
    "#    proxies_list = [\"220.129.196.210:443\", \"114.40.169.86:443\"]\n",
    "#    proxies = {\n",
    "#        'https': random.choice(proxies_list)\n",
    "#    }\n",
    "    response_first = r.request(\"POST\", url_first, data=payload_first, headers=headers_first, params=querystring_first)\n",
    "    print response_first\n",
    "    response_first.encoding = 'utf8'\n",
    "    url_soup_first = BeautifulSoup(response_first.text, 'lxml')\n",
    "    first = url_soup_first.find('a', class_=\"title\")\n",
    "    print first\n",
    "    \n",
    "    i = 0\n",
    "    payload_list = []\n",
    "    \n",
    "    while( i > -1 ):\n",
    "        # create payload for request, from o, get 60 posts each time\n",
    "        payload = \"-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"start\\\"\\r\\n\\r\\n0\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"num\\\"\\r\\n\\r\\n60\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"numChildren\\\"\\r\\n\\r\\n0\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"ipf\\\"\\r\\n\\r\\n1\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"xhr\\\"\\r\\n\\r\\n1\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"h1\\\"\\r\\n\\r\\nzh_TW\\r\\n-----011000010111000001101001--\"\n",
    "        url_forPayLoad = url\n",
    "        querystring = querystring\n",
    "        headers = headers\n",
    "#    proxies_list = [\"220.129.196.210:443\", \"114.40.169.86:443\"]\n",
    "#    proxies = {\n",
    "#        'https': random.choice(proxies_list)\n",
    "#    }\n",
    "        response = r.request(\"POST\", url_forPayLoad, data=payload, headers=headers, params=querystring)\n",
    "        response.encoding = 'utf8'\n",
    "        url_soup = BeautifulSoup(response.text, 'lxml')\n",
    "#        print url_soup\n",
    "        # for checking if  get repeat url, get first url to campare\n",
    "        lists_first = url_soup.find('a', class_=\"title\")\n",
    "#        print lists_first\n",
    "        # in some case, first url might be empty if payload is out of range\n",
    "        if lists_first == None:\n",
    "            return payload_list\n",
    "        else:            \n",
    "#        print lists\n",
    "            # for the first request, append lists anyway\n",
    "            if i == 0:\n",
    "                payload_list.append(payload)\n",
    "                i += 60\n",
    "            # if first url = first or empty, stop the loop and return the payload lists -> this means payload is outof range, so need to stop\n",
    "            elif lists_first == first or lists_first == '' '':\n",
    "                return payload_list\n",
    "            # others append lists\n",
    "            else:\n",
    "                payload_list.append(payload)\n",
    "                i += 60\n",
    "    # return the lists of payload\n",
    "    return payload_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def url_lists(response):\n",
    "    \"\"\" This is the founction for getting each movie's url from a payload list        \n",
    "          arg = \"response\"\n",
    "          return = url_lists [\n",
    "                          url,\n",
    "                          url\n",
    "                          ......          ]\n",
    "    \n",
    "    \"\"\"\n",
    "    url_soup = BeautifulSoup(response.text, 'lxml')\n",
    "    lists = url_soup.find_all('a', class_=\"title\")\n",
    "    url_lists = []\n",
    "    # for a single response it will contain 60 movie urls\n",
    "    for url in lists:\n",
    "        url_lists.append(url['href'])\n",
    "#        print len(url_lists)\n",
    "    return url_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_basic_info(url, playid):\n",
    "    \"\"\" This is the function for each movie's basic information\n",
    "          arg = url_lists\n",
    "          return = movie_info_list [title, total_star,  total_num]\n",
    "    \"\"\"\n",
    "    movie_info_list = []\n",
    "    \n",
    "    url = url\n",
    "    querystring = {\"id\":playid , \"authuser\":\"0\"}\n",
    "    payload = \"-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"ipf\\\"\\r\\n\\r\\n1\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"xhr\\\"\\r\\n\\r\\n1\\r\\n-----011000010111000001101001--\"\n",
    "    headers = {\n",
    "        'content-type': \"multipart/form-data; boundary=---011000010111000001101001\",\n",
    "        'cache-control': \"no-cache\",\n",
    "#        'postman-token': \"9bfafe06-84ee-ed77-bc09-8df3c9f44137\"\n",
    "        }\n",
    "#    proxies_list = [\"220.129.196.210:443\", \"114.40.169.86:443\"]\n",
    "#    proxies = {\n",
    "#        'https': random.choice(proxies_list)\n",
    "#    }\n",
    "    response = r.request(\"POST\", url, data=payload, headers=headers, params=querystring)\n",
    "    response.encoding = 'utf-8'\n",
    "    content_soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    # get each movie's title & total_star & total_num\n",
    "    try:\n",
    "        total_star = content_soup.find('div', class_=\"tiny-star\")['aria-label']\n",
    "        total_num = content_soup.find('span', class_=\"reviewers-small\")['aria-label']\n",
    "        title = content_soup.find(class_=\"document-title\").text.strip()\n",
    "\n",
    "        movie_info_list.append(title)\n",
    "        movie_info_list.append(total_star)\n",
    "        movie_info_list.append(total_num)\n",
    "#        print movie_info_list\n",
    "    # if there were no one comment, there's no total star. catch the exception, and given the total_star=0 & total_num=0\n",
    "    except:\n",
    "        total_star = \"0\"\n",
    "        total_num = \"0\"\n",
    "        title = content_soup.find(class_=\"document-title\").text.strip()\n",
    "        \n",
    "        movie_info_list.append(title)\n",
    "        movie_info_list.append(total_star)\n",
    "        movie_info_list.append(total_num)\n",
    "#        print movie_info_lists\n",
    "    time.sleep(1)\n",
    "    return movie_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_reviews(movie_id):\n",
    "    \"\"\" This is the function for getting each movie's total reviews\n",
    "          arg = movie_id # movie_id is for payload\n",
    "          return = all_reviews = {\n",
    "                      user : star,\n",
    "                      user : star          }\n",
    "    \"\"\"\n",
    "    single_movie_dict = {}\n",
    "    \n",
    "    url = \"http://play.google.com/store/getreviews\"\n",
    "    querystring = {\"authuser\":\"0\"}\n",
    "       \n",
    "    headers = {\n",
    "        'content-type': \"multipart/form-data; boundary=---011000010111000001101001; charset=UTF-8\",\n",
    "        'cache-control': \"no-cache\",\n",
    "#        'postman-token': \"f69f4f7b-9d24-94c1-466f-91c4e72bde82\",\n",
    "        }\n",
    "    \n",
    "    page = 0\n",
    "    while (page > -1):\n",
    "        payload = \"-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"reviewType\\\"\\r\\n\\r\\n0\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"pageNum\\\"\\r\\n\\r\\n\" + str(page) + \"\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"id\\\"\\r\\n\\r\\nmovie-\" + str(movie_id) + \"\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"reviewSortOrder\\\"\\r\\n\\r\\n4\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"xhr\\\"\\r\\n\\r\\n1\\r\\n-----011000010111000001101001--\"\n",
    "        \n",
    "#    proxies_list = [\"220.129.196.210:443\", \"114.40.169.86:443\"]\n",
    "#    proxies = {\n",
    "#        'https': random.choice(proxies_list)\n",
    "#    }\n",
    "        response = r.request(\"POST\", url, data=payload, headers=headers, params=querystring)\n",
    "        response.encoding = 'utf-8'\n",
    "        \n",
    "        #  if len(response.text.split(\",\")) == 2 means there's no commend, return an empty all_reviews\n",
    "        if len(response.text.split(\",\")) == 2:\n",
    "            return single_movie_dict\n",
    "        \n",
    "        # if response.text.split(\",\")[2] == \"\" means payload is out of range, return all_reviews\n",
    "        elif response.text.split(\",\")[2] == u'\"\"':\n",
    "            return single_movie_dict\n",
    "        \n",
    "        # else is the normal reviews \n",
    "        else:\n",
    "            # response is a json like document, replace unicode to characters fro further BeautifulSoup\n",
    "            a = response.text.replace(\"\\u003c\", \"<\").replace(\"\\u003d\", \"=\").replace(\"\\u003e\", \">\").replace('\\\\\"', '\"')\n",
    "            soup = BeautifulSoup(a[17:-7], 'lxml')\n",
    " \n",
    "            # get all reviews from one request\n",
    "            single_review = soup.find_all('div', class_=\"review-info\")\n",
    "            # get each review\n",
    "            for single in single_review:\n",
    "                user = single.find('span', class_=\"author-name\").text.replace(\".\", \" \")\n",
    "                star_long = single.find('div', class_=\"tiny-star\")[\"aria-label\"]\n",
    "                star = star_long.split(\" \")[1]\n",
    "                single_movie_dict.update({user : star})                \n",
    "            page += 1 # page plus one for next page of reviews\n",
    "        time.sleep(3)\n",
    "    return single_movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_info(url_lists, num):\n",
    "    \"\"\" This is the function for each movie's review\n",
    "          arg = url_lists\n",
    "          return = \n",
    "          OutPut = one json for one movie to Mongo DB\n",
    "                          movie = { \"title\" : \"\", \"type\" : \"\", \"rating\": \"\", \"total_num\": \"\",  \"reviews\" : \"\" }\n",
    "    \"\"\"\n",
    "    now = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    url_left = \"http://play.google.com\"    \n",
    "    category = num\n",
    "    count = 1\n",
    "    \n",
    "    # run each movie url\n",
    "    for single_url in url_lists:\n",
    "        \n",
    "        movie = {}\n",
    "        \n",
    "        # total_url is create for request\n",
    "        total_url = url_left + single_url.split(\"?\")[0]\n",
    "        \n",
    "        # movie_id is create for querystring\n",
    "        movie_id = str(single_url.split(\"?\")[1].split(\"=\")[1])\n",
    "        \n",
    "        # call movie_basic_info() for movie's basic information, get a list of [title, total_star,  total_num]\n",
    "        basic = movie_basic_info(total_url, movie_id)\n",
    "        \n",
    "        # call movie_reviews() function for total reviews, get a dict of user reviews\n",
    "        total_reviews = movie_reviews(movie_id)\n",
    "        \n",
    "        # insert data into movie\n",
    "        movie.update({\"title\" : basic[0]})\n",
    "        movie.update({\"type\" : category})\n",
    "        movie.update({\"rating\" : basic[1]})\n",
    "        movie.update({\"total_num\" : basic[2]})\n",
    "        movie.update({\"reviews\" : total_reviews})\n",
    "        \n",
    "        # output movie into MongoDB\n",
    "        collect.insert_one(movie)\n",
    "        print now + '\\t' + basic[0] + '\\n' + single_url\n",
    "        print count\n",
    "    \n",
    "        # count for total number of output\n",
    "        count += 1\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def google_play_movie(category):\n",
    "    \"\"\" This is the main function to crawle google play movie\n",
    "          arg = \"num\" #catogory number\n",
    "          return = \"Crawler finised! with total insert number\"\n",
    "    \"\"\"\n",
    "    # lists for 熱門電影 urls\n",
    "    top_urls = []\n",
    "    # lists for 新片上架 urls\n",
    "    mo_urls = []\n",
    "    number_insert_top = 0\n",
    "    number_insert_mo = 0\n",
    "    \n",
    "    for num in category:\n",
    "        \n",
    "        # 熱門電影 = top\n",
    "        url_top = \"http://play.google.com/store/movies/category/\" + str(num) + \"/collection/topselling_paid\"\n",
    "        # 新片上架 = mo\n",
    "        url_mo = \"http://play.google.com/store/movies/category/\" + str(num) + \"/collection/movers_shakers\"\n",
    "\n",
    "        querystring = {\"authuser\":\"0\"}\n",
    "        headers = {\n",
    "            'content-type': \"multipart/form-data; boundary=---011000010111000001101001\",\n",
    "            'cache-control': \"no-cache\",\n",
    "            'postman-token': \"f5c415de-8ec3-1c1b-28bf-0598323cfa8f\"\n",
    "            }\n",
    "#    proxies_list = [\"220.129.196.210:443\", \"114.40.169.86:443\"]\n",
    "#    proxies = {\n",
    "#        'https': random.choice(proxies_list)\n",
    "#    }\n",
    "        \n",
    "        # for payload, call create_payload() function\n",
    "        payload_list_top = create_payload(url_top, querystring, headers)\n",
    "        payload_list_mo = create_payload(url_mo, querystring, headers)\n",
    "        print payload_list_top\n",
    "        \n",
    "        # use payload to request movies\n",
    "        for payload_top in payload_list_top:\n",
    "            response_top = r.request(\"POST\", url_top, data=payload_top, headers=headers, params=querystring)\n",
    "            response_top.encoding = 'utf8'\n",
    "            # call url_lists() function to get urls from each response\n",
    "            top_url_lists = url_lists(response_top)\n",
    "            # call movie_info() function to get all informations for each url, !!!OutPut to MongoDB by this function!!!\n",
    "            number_insert_top = movie_info(top_url_lists, num)\n",
    "        \n",
    "        # same for the mo\n",
    "        for payload_mo in payload_list_mo:\n",
    "            response_mo = r.request(\"POST\", url_mo, data=payload_mo, headers=headers, params=querystring)\n",
    "            response_mo.encoding = 'utf8'\n",
    "            mo_url_lists = url_lists(response_mo)\n",
    "            number_insert_mo = movie_info(mo_url_lists, num)\n",
    "        \n",
    "        # count for the total number of movies insert into MongoDB\n",
    "        total_insert_number = int(number_insert_top) + int(number_insert_mo)\n",
    "    \n",
    "    return \"Crawler finised!\" + str(total_insert_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "http://play.google.com/store/movies/category/1/collection/topselling_paid\n",
      "{'authuser': '0'}\n",
      "{'postman-token': 'f5c415de-8ec3-1c1b-28bf-0598323cfa8f', 'content-type': 'multipart/form-data; boundary=---011000010111000001101001', 'cache-control': 'no-cache'}\n",
      "<Response [400]>\n",
      "None\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', error(10060, '\\xb3s\\xbdu\\xb9\\xc1\\xb8\\xd5\\xa5\\xa2\\xb1\\xd1\\xa1A\\xa6]\\xac\\xb0\\xb3s\\xbdu\\xb9\\xef\\xb6H\\xa6\\xb3\\xa4@\\xacq\\xae\\xc9\\xb6\\xa1\\xa8\\xc3\\xa5\\xbc\\xa5\\xbf\\xbdT\\xa6^\\xc0\\xb3\\xa1A\\xa9\\xce\\xacO\\xb3s\\xbdu\\xab\\xd8\\xa5\\xdf\\xa5\\xa2\\xb1\\xd1\\xa1A\\xa6]\\xac\\xb0\\xb3s\\xbdu\\xaa\\xba\\xa5D\\xbe\\xf7\\xb5L\\xaak\\xa6^\\xc0\\xb3\\xa1C'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-3f0be90cb626>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgoogle_play_movie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-ceee8c45038d>\u001b[0m in \u001b[0;36mgoogle_play_movie\u001b[1;34m(category)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# for payload, call create_payload() function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mpayload_list_top\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_payload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_top\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquerystring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mpayload_list_mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_payload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquerystring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mpayload_list_top\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-27bdb13f845b>\u001b[0m in \u001b[0;36mcreate_payload\u001b[1;34m(url, querystring, headers)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m#        'https': random.choice(proxies_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m#    }\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_forPayLoad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquerystring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0murl_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\requests\\api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    473\u001b[0m         }\n\u001b[0;32m    474\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\requests\\adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', error(10060, '\\xb3s\\xbdu\\xb9\\xc1\\xb8\\xd5\\xa5\\xa2\\xb1\\xd1\\xa1A\\xa6]\\xac\\xb0\\xb3s\\xbdu\\xb9\\xef\\xb6H\\xa6\\xb3\\xa4@\\xacq\\xae\\xc9\\xb6\\xa1\\xa8\\xc3\\xa5\\xbc\\xa5\\xbf\\xbdT\\xa6^\\xc0\\xb3\\xa1A\\xa9\\xce\\xacO\\xb3s\\xbdu\\xab\\xd8\\xa5\\xdf\\xa5\\xa2\\xb1\\xd1\\xa1A\\xa6]\\xac\\xb0\\xb3s\\xbdu\\xaa\\xba\\xa5D\\xbe\\xf7\\xb5L\\xaak\\xa6^\\xc0\\xb3\\xa1C'))"
     ]
    }
   ],
   "source": [
    "google_play_movie([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
